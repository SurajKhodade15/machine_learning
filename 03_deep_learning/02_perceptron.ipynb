{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092e286a",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Theoretical Intuition\n",
    "- A **Perceptron** is the **simplest type of artificial neural network** (ANN).  \n",
    "- It is a **binary classifier** that maps input features to an output using a **linear combination of weights** and an **activation function**.  \n",
    "- Introduced by **Frank Rosenblatt (1958)**.  \n",
    "- Think of it as a **single neuron in the brain**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Key Pointers\n",
    "- It works for **linearly separable data**.  \n",
    "- Inputs (**x1, x2, ... xn**) are multiplied by weights (**w1, w2, ... wn**) and summed up with a **bias** term.  \n",
    "- Output is passed through a **step activation function** (0 or 1).  \n",
    "- **Learning**: weights are updated based on **prediction error** using the **Perceptron learning rule**.  \n",
    "- Limitation: Cannot solve **non-linear problems** like XOR.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Use Cases\n",
    "- Early **binary classification tasks**  \n",
    "- Simple **pattern recognition**  \n",
    "- Foundation for **more complex neural networks**  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. Mathematical Intuition\n",
    "- Weighted sum:  \n",
    "\n",
    "\\[\n",
    "z = w_1 x_1 + w_2 x_2 + ... + w_n x_n + b\n",
    "\\]\n",
    "\n",
    "- Activation function (step):  \n",
    "\n",
    "\\[\n",
    "y =\n",
    "\\begin{cases} \n",
    "1 & \\text{if } z \\ge 0 \\\\\n",
    "0 & \\text{if } z < 0\n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "- Weight update (Perceptron learning rule):  \n",
    "\n",
    "\\[\n",
    "w_i = w_i + \\Delta w_i\n",
    "\\]  \n",
    "\n",
    "\\[\n",
    "\\Delta w_i = \\eta (y_{\\text{true}} - y_{\\text{pred}}) x_i\n",
    "\\]  \n",
    "\n",
    "where **η** = learning rate, **y_true** = actual label, **y_pred** = predicted label.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Interview Q&A\n",
    "\n",
    "| Question | Answer |\n",
    "|----------|--------|\n",
    "| What is a Perceptron? | The simplest type of neural network; a binary classifier that uses weighted sum and activation. |\n",
    "| Who introduced the Perceptron? | Frank Rosenblatt in 1958. |\n",
    "| How does a Perceptron make predictions? | Computes weighted sum of inputs + bias, passes through step function. |\n",
    "| What is the main limitation of a Perceptron? | Cannot solve non-linear problems like XOR. |\n",
    "| What is the Perceptron learning rule? | Updates weights based on prediction error: w_i = w_i + η*(y_true - y_pred)*x_i |\n",
    "| What type of data can a Perceptron classify? | Linearly separable data. |\n",
    "| Why do we need bias in a Perceptron? | Allows shifting the decision boundary away from the origin. |\n",
    "| Can a single Perceptron be used for multi-class classification? | No, only binary; multi-class requires multiple Perceptrons or other architectures. |\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Code Demo: Simple Perceptron in Python\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Step activation function\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, lr=0.1, epochs=10):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.bias = 0\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def predict(self, x):\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        return step(z)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.epochs):\n",
    "            for xi, yi in zip(X, y):\n",
    "                y_pred = self.predict(xi)\n",
    "                update = self.lr * (yi - y_pred)\n",
    "                self.weights += update * xi\n",
    "                self.bias += update\n",
    "\n",
    "# Training data: AND gate\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "# Train Perceptron\n",
    "p = Perceptron(input_size=2)\n",
    "p.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "for xi in X:\n",
    "    print(f\"Input: {xi}, Predicted: {p.predict(xi)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18ae21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
